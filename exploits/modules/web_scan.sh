#!/bin/bash

# ============================================================================
# Web Vulnerability Scanning Module for CVEHACK
# ============================================================================

# Source required libraries
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/../lib/colors.sh"
source "$SCRIPT_DIR/../lib/logger.sh"

# ============================================================================
# Web Scanning Menu
# ============================================================================

show_web_scan_menu() {
    local target="$1"
    
    while true; do
        clear_screen
        section_header "🛡️ Web Vulnerability Scanning & Assessment"
        
        echo -e "${GREEN}Target: ${YELLOW}$target${NC}"
        echo ""
        echo -e "${YELLOW}1.${NC} 🌐 Web Server Vulnerability Scan (Nikto)"
        echo -e "${YELLOW}2.${NC} 📁 Directory & File Brute Force"
        echo -e "${YELLOW}3.${NC} 💉 SQL Injection Testing"
        echo -e "${YELLOW}4.${NC} 🔍 WordPress Security Scan"
        echo -e "${YELLOW}5.${NC} 🕸️ Cross-Site Scripting (XSS) Testing"
        echo -e "${YELLOW}6.${NC} 🔐 Authentication Bypass Testing"
        echo -e "${YELLOW}7.${NC} 📋 Web Application Fingerprinting"
        echo -e "${YELLOW}8.${NC} 🔗 Broken Link & Resource Analysis"
        echo -e "${YELLOW}9.${NC} 📊 HTTP Security Headers Analysis"
        echo -e "${YELLOW}10.${NC} 🚀 Comprehensive Web Assessment"
        echo ""
        echo -e "${YELLOW}0.${NC} 🔙 Back to Main Menu"
        echo ""
        echo -e "${BLUE}Select web scanning option: ${NC}"
        read -r web_choice
        
        case $web_choice in
            1) nikto_web_scan "$target" ;;
            2) directory_brute_force "$target" ;;
            3) sql_injection_testing "$target" ;;
            4) wordpress_security_scan "$target" ;;
            5) xss_testing "$target" ;;
            6) auth_bypass_testing "$target" ;;
            7) web_app_fingerprinting "$target" ;;
            8) broken_link_analysis "$target" ;;
            9) http_security_headers "$target" ;;
            10) full_web_scan "$target" ;;
            0) return ;;
            *) print_error "Invalid option. Please try again." ;;
        esac
        
        echo ""
        print_info "Press Enter to continue..."
        read -r
    done
}

# ============================================================================
# Nikto Web Server Vulnerability Scan
# ============================================================================

nikto_web_scan() {
    local target="$1"
    
    subsection_header "Web Server Vulnerability Scan (Nikto)"
    log_scan_start "Nikto Web Scan" "$target"
    
    print_info "Starting Nikto web vulnerability scan on $target..."
    
    if ! command -v nikto &> /dev/null; then
        print_error "Nikto not found. Please install nikto first."
        return 1
    fi
    
    # Ensure target has protocol
    if [[ ! "$target" =~ ^https?:// ]]; then
        # Try HTTPS first, then HTTP
        if curl -s --connect-timeout 5 "https://$target" >/dev/null 2>&1; then
            target="https://$target"
        else
            target="http://$target"
        fi
    fi
    
    print_info "Target URL: $target"
    print_warning "This scan may take several minutes..."
    
    # Run Nikto scan
    local nikto_output=$(nikto -h "$target" -Format txt 2>/dev/null)
    
    if [[ -n "$nikto_output" ]]; then
        print_success "Nikto scan completed"
        
        # Parse and categorize findings
        local vulnerability_count=0
        local info_count=0
        
        echo "$nikto_output" | while IFS= read -r line; do
            if [[ "$line" =~ ^\+.*OSVDB ]]; then
                ((vulnerability_count++))
                print_warning "Vulnerability: $(echo "$line" | sed 's/^+ //')"
                
                # Log as vulnerability if it contains certain keywords
                if echo "$line" | grep -qi "injection\|xss\|csrf\|directory traversal\|file inclusion"; then
                    local vuln_type=$(echo "$line" | grep -oiE "injection|xss|csrf|directory traversal|file inclusion" | head -1)
                    log_vulnerability "$vuln_type" "MEDIUM" "$target" "Nikto detected potential vulnerability" "$line"
                fi
                
            elif [[ "$line" =~ ^\+.*Server ]]; then
                print_info "Server Info: $(echo "$line" | sed 's/^+ //')"
                ((info_count++))
                
            elif [[ "$line" =~ ^\+.*Retrieved ]]; then
                print_success "Discovery: $(echo "$line" | sed 's/^+ //')"
                ((info_count++))
                
            elif [[ "$line" =~ ^\+.*Cookie ]]; then
                print_warning "Cookie Issue: $(echo "$line" | sed 's/^+ //')"
                
            elif [[ "$line" =~ ^\+.*Header ]]; then
                print_info "Header Info: $(echo "$line" | sed 's/^+ //')"
            fi
        done
        
        print_info "Scan Summary:"
        print_info "  Potential vulnerabilities: $vulnerability_count"
        print_info "  Information disclosures: $info_count"
        
        # Check for specific high-risk findings
        if echo "$nikto_output" | grep -qi "admin\|phpmyadmin\|backup\|config"; then
            print_warning "Sensitive directories or files may be accessible"
        fi
        
        if echo "$nikto_output" | grep -qi "outdated\|vulnerable"; then
            print_error "Outdated or vulnerable software components detected"
        fi
        
    else
        print_error "Nikto scan failed or produced no output"
        return 1
    fi
    
    save_scan_data "nikto_scan" "$target" "$nikto_output"
    log_scan_result "Nikto Web Scan" "$target" "$nikto_output"
    
    print_success "Nikto web vulnerability scan completed"
}

# ============================================================================
# Directory & File Brute Force
# ============================================================================

directory_brute_force() {
    local target="$1"
    
    subsection_header "Directory & File Brute Force"
    log_scan_start "Directory Brute Force" "$target"
    
    print_info "Starting directory and file brute force on $target..."
    
    # Ensure target has protocol
    if [[ ! "$target" =~ ^https?:// ]]; then
        if curl -s --connect-timeout 5 "https://$target" >/dev/null 2>&1; then
            target="https://$target"
        else
            target="http://$target"
        fi
    fi
    
    local brute_results=""
    
    # Using gobuster if available
    if command -v gobuster &> /dev/null; then
        print_info "Using gobuster for directory enumeration..."
        
        # Create a basic wordlist if none exists
        local wordlist="/tmp/cvehack_dirs.txt"
        create_directory_wordlist "$wordlist"
        
        local gobuster_output=$(gobuster dir -u "$target" -w "$wordlist" -q -t 20 2>/dev/null)
        
        if [[ -n "$gobuster_output" ]]; then
            brute_results="Gobuster Results:
$gobuster_output"
            
            print_success "Gobuster scan completed"
            echo "$gobuster_output" | while read -r line; do
                if [[ "$line" =~ ^/.* ]]; then
                    local path=$(echo "$line" | awk '{print $1}')
                    local status=$(echo "$line" | awk '{print $2}')
                    local size=$(echo "$line" | awk '{print $3}')
                    
                    case "$status" in
                        "200")
                            print_success "Found: $path (Status: $status, Size: $size)"
                            ;;
                        "301"|"302")
                            print_info "Redirect: $path (Status: $status)"
                            ;;
                        "403")
                            print_warning "Forbidden: $path (Status: $status)"
                            ;;
                        "401")
                            print_warning "Unauthorized: $path (Status: $status)"
                            ;;
                    esac
                fi
            done
        fi
        
        rm -f "$wordlist"
        
    # Using dirb as fallback
    elif command -v dirb &> /dev/null; then
        print_info "Using dirb for directory enumeration..."
        local dirb_output=$(dirb "$target" -S -w 2>/dev/null)
        
        if [[ -n "$dirb_output" ]]; then
            brute_results="Dirb Results:
$dirb_output"
            
            print_success "Dirb scan completed"
            echo "$dirb_output" | grep "==> DIRECTORY:" | while read -r line; do
                local dir=$(echo "$line" | awk '{print $3}')
                print_success "Directory found: $dir"
            done
            
            echo "$dirb_output" | grep "CODE:" | while read -r line; do
                local url=$(echo "$line" | awk '{print $1}')
                local code=$(echo "$line" | awk '{print $3}')
                print_info "File found: $url (Code: $code)"
            done
        fi
        
    else
        print_warning "No directory brute force tools available. Performing manual checks..."
        manual_directory_check "$target"
    fi
    
    # Check for common sensitive files
    print_info "Checking for sensitive files..."
    check_sensitive_files "$target"
    
    save_scan_data "directory_brute_force" "$target" "$brute_results"
    log_scan_result "Directory Brute Force" "$target" "$brute_results"
    
    print_success "Directory and file brute force completed"
}

create_directory_wordlist() {
    local wordlist="$1"
    
    cat > "$wordlist" << 'EOF'
admin
administrator
login
wp-admin
wp-login
phpmyadmin
mysql
database
db
backup
backups
config
configuration
test
testing
dev
development
staging
api
docs
documentation
help
support
images
img
css
js
javascript
assets
uploads
files
download
downloads
temp
tmp
cache
logs
log
error
errors
include
includes
lib
library
src
source
bin
cgi-bin
scripts
data
xml
json
txt
pdf
zip
tar
gz
sql
bak
old
new
1
2
3
admin.php
login.php
index.php
config.php
test.php
info.php
phpinfo.php
robots.txt
sitemap.xml
.htaccess
.git
.svn
.env
EOF
}

manual_directory_check() {
    local target="$1"
    
    local common_paths=("admin" "login" "wp-admin" "phpmyadmin" "config" "backup" "test" "api" "docs")
    
    for path in "${common_paths[@]}"; do
        local test_url="$target/$path"
        local response=$(curl -s -o /dev/null -w "%{http_code}" "$test_url" 2>/dev/null)
        
        case "$response" in
            "200")
                print_success "Found: /$path (HTTP $response)"
                ;;
            "301"|"302")
                print_info "Redirect: /$path (HTTP $response)"
                ;;
            "403")
                print_warning "Forbidden: /$path (HTTP $response)"
                ;;
            "401")
                print_warning "Unauthorized: /$path (HTTP $response)"
                ;;
        esac
    done
}

check_sensitive_files() {
    local target="$1"
    
    local sensitive_files=("robots.txt" "sitemap.xml" ".htaccess" ".env" "config.php" "wp-config.php" "database.php" "phpinfo.php" "info.php" "test.php" "backup.sql" "dump.sql" ".git/config" ".svn/entries")
    
    for file in "${sensitive_files[@]}"; do
        local test_url="$target/$file"
        local response=$(curl -s -o /dev/null -w "%{http_code}" "$test_url" 2>/dev/null)
        
        if [[ "$response" == "200" ]]; then
            print_error "Sensitive file accessible: /$file"
            log_vulnerability "Information Disclosure" "MEDIUM" "$target" "Sensitive file accessible: $file" "HTTP 200 response for $test_url"
        elif [[ "$response" == "403" ]]; then
            print_warning "Sensitive file exists but forbidden: /$file"
        fi
    done
}

# ============================================================================
# SQL Injection Testing
# ============================================================================

sql_injection_testing() {
    local target="$1"
    
    subsection_header "SQL Injection Testing"
    log_scan_start "SQL Injection Testing" "$target"
    
    print_info "Starting SQL injection testing on $target..."
    
    if ! command -v sqlmap &> /dev/null; then
        print_error "SQLMap not found. Please install sqlmap first."
        return 1
    fi
    
    # Ensure target has protocol
    if [[ ! "$target" =~ ^https?:// ]]; then
        if curl -s --connect-timeout 5 "https://$target" >/dev/null 2>&1; then
            target="https://$target"
        else
            target="http://$target"
        fi
    fi
    
    print_info "Target URL: $target"
    print_warning "This test may take several minutes and generate significant traffic..."
    
    # Basic SQL injection test
    print_info "Performing basic SQL injection detection..."
    local sqlmap_output=$(sqlmap -u "$target" --batch --level=1 --risk=1 --dbs --timeout=30 2>/dev/null)
    
    if [[ -n "$sqlmap_output" ]]; then
        print_success "SQLMap scan completed"
        
        # Check for vulnerabilities
        if echo "$sqlmap_output" | grep -qi "vulnerable"; then
            print_error "SQL injection vulnerability detected!"
            
            # Extract vulnerability details
            local vuln_details=$(echo "$sqlmap_output" | grep -A 5 -B 5 "vulnerable")
            log_vulnerability "SQL Injection" "HIGH" "$target" "SQLMap detected SQL injection vulnerability" "$vuln_details"
            
            # Try to extract database information
            if echo "$sqlmap_output" | grep -qi "available databases"; then
                print_warning "Database information disclosed:"
                echo "$sqlmap_output" | grep -A 10 "available databases" | while read -r line; do
                    if [[ "$line" =~ ^\[.*\].*[a-zA-Z] ]]; then
                        print_info "  Database: $(echo "$line" | sed 's/\[.*\] //')"
                    fi
                done
            fi
            
        elif echo "$sqlmap_output" | grep -qi "not vulnerable"; then
            print_success "No SQL injection vulnerabilities detected"
            
        else
            print_warning "SQL injection test completed with uncertain results"
        fi
        
        # Check for WAF detection
        if echo "$sqlmap_output" | grep -qi "WAF\|firewall"; then
            print_info "Web Application Firewall (WAF) detected"
        fi
        
    else
        print_error "SQLMap scan failed or produced no output"
        
        # Perform manual SQL injection tests
        print_info "Performing manual SQL injection tests..."
        manual_sql_injection_test "$target"
    fi
    
    save_scan_data "sql_injection_test" "$target" "$sqlmap_output"
    log_scan_result "SQL Injection Testing" "$target" "$sqlmap_output"
    
    print_success "SQL injection testing completed"
}

manual_sql_injection_test() {
    local target="$1"
    
    print_info "Testing common SQL injection payloads..."
    
    local sql_payloads=("'" "\"" "1' OR '1'='1" "1\" OR \"1\"=\"1" "'; DROP TABLE users; --" "1' UNION SELECT NULL--")
    
    for payload in "${sql_payloads[@]}"; do
        local test_url="${target}?id=${payload// /%20}"
        local response=$(curl -s "$test_url" 2>/dev/null)
        
        # Check for SQL error messages
        if echo "$response" | grep -qi "sql\|mysql\|oracle\|postgresql\|sqlite\|error\|warning"; then
            print_warning "Potential SQL injection point detected with payload: $payload"
            
            # Check for specific error patterns
            if echo "$response" | grep -qi "syntax error\|mysql_fetch\|ORA-\|PostgreSQL"; then
                print_error "SQL error message detected - likely vulnerable!"
                log_vulnerability "SQL Injection" "HIGH" "$target" "Manual SQL injection test detected error messages" "Payload: $payload, Response contains SQL errors"
            fi
        fi
    done
}

# ============================================================================
# WordPress Security Scan
# ============================================================================

wordpress_security_scan() {
    local target="$1"
    
    subsection_header "WordPress Security Scan"
    log_scan_start "WordPress Security Scan" "$target"
    
    print_info "Starting WordPress security scan on $target..."
    
    # Ensure target has protocol
    if [[ ! "$target" =~ ^https?:// ]]; then
        if curl -s --connect-timeout 5 "https://$target" >/dev/null 2>&1; then
            target="https://$target"
        else
            target="http://$target"
        fi
    fi
    
    local wp_results=""
    
    # Use custom WordPress scanner
    if [[ -f "$SCRIPT_DIR/../cve/tools/custom_wordpress_scanner.sh" ]]; then
        print_info "Using custom WordPress security scanner..."
        chmod +x "$SCRIPT_DIR/../cve/tools/custom_wordpress_scanner.sh"
        
        local custom_wp_output=$("$SCRIPT_DIR/../cve/tools/custom_wordpress_scanner.sh" "$target" -u -p -t 2>/dev/null)
        
        if [[ -n "$custom_wp_output" ]]; then
            wp_results="Custom WordPress Scanner Results:
$custom_wp_output"
            
            print_success "Custom WordPress scan completed"
            echo "$custom_wp_output"
            
        else
            print_warning "Custom WordPress scanner failed. Performing manual checks..."
            manual_wordpress_check "$target"
        fi
        
    else
        print_warning "Custom WordPress scanner not available. Performing manual WordPress security checks..."
        manual_wordpress_check "$target"
    fi
    
    save_scan_data "wordpress_scan" "$target" "$wp_results"
    log_scan_result "WordPress Security Scan" "$target" "$wp_results"
    
    print_success "WordPress security scan completed"
}

manual_wordpress_check() {
    local target="$1"
    
    print_info "Performing manual WordPress security checks..."
    
    # Check WordPress version
    print_info "Checking WordPress version..."
    local wp_version=$(curl -s "$target" 2>/dev/null | grep -o 'content="WordPress [0-9.]*"' | grep -o '[0-9.]*')
    if [[ -n "$wp_version" ]]; then
        print_success "WordPress version detected: $wp_version"
        
        # Check if version is outdated (simplified check)
        if [[ "$wp_version" < "6.0" ]]; then
            print_warning "WordPress version may be outdated"
            log_vulnerability "Outdated Software" "MEDIUM" "$target" "WordPress version $wp_version may be outdated" "Detected version: $wp_version"
        fi
    fi
    
    # Check for common WordPress vulnerabilities
    print_info "Checking for common WordPress security issues..."
    
    # Check wp-config.php accessibility
    local wp_config_response=$(curl -s -o /dev/null -w "%{http_code}" "$target/wp-config.php" 2>/dev/null)
    if [[ "$wp_config_response" == "200" ]]; then
        print_error "wp-config.php is accessible!"
        log_vulnerability "Information Disclosure" "CRITICAL" "$target" "wp-config.php file is accessible" "HTTP 200 response for wp-config.php"
    fi
    
    # Check for directory listing
    local wp_content_response=$(curl -s "$target/wp-content/" 2>/dev/null)
    if echo "$wp_content_response" | grep -qi "index of"; then
        print_warning "Directory listing enabled for wp-content"
        log_vulnerability "Information Disclosure" "LOW" "$target" "Directory listing enabled" "wp-content directory listing accessible"
    fi
    
    # Check for common backup files
    local backup_files=("wp-config.php.bak" "wp-config.php.old" "wp-config.php~" "backup.sql" "database.sql")
    for backup in "${backup_files[@]}"; do
        local backup_response=$(curl -s -o /dev/null -w "%{http_code}" "$target/$backup" 2>/dev/null)
        if [[ "$backup_response" == "200" ]]; then
            print_error "Backup file accessible: $backup"
            log_vulnerability "Information Disclosure" "HIGH" "$target" "Backup file accessible: $backup" "HTTP 200 response"
        fi
    done
    
    # Check for user enumeration
    print_info "Testing user enumeration..."
    local user_enum_response=$(curl -s "$target/?author=1" 2>/dev/null)
    if echo "$user_enum_response" | grep -qi "author\|user"; then
        print_warning "User enumeration may be possible"
        log_vulnerability "Information Disclosure" "LOW" "$target" "User enumeration possible via author parameter" "Author enumeration successful"
    fi
}

# ============================================================================
# Web Application Fingerprinting
# ============================================================================

web_app_fingerprinting() {
    local target="$1"
    
    subsection_header "Web Application Fingerprinting"
    log_scan_start "Web Application Fingerprinting" "$target"
    
    print_info "Starting web application fingerprinting on $target..."
    
    # Ensure target has protocol
    if [[ ! "$target" =~ ^https?:// ]]; then
        if curl -s --connect-timeout 5 "https://$target" >/dev/null 2>&1; then
            target="https://$target"
        else
            target="http://$target"
        fi
    fi
    
    local fingerprint_results=""
    
    # Use custom web technology scanner
    if [[ -f "$SCRIPT_DIR/../cve/tools/custom_webtech_scanner.sh" ]]; then
        print_info "Using custom web technology scanner..."
        chmod +x "$SCRIPT_DIR/../cve/tools/custom_webtech_scanner.sh"
        
        local webtech_output=$("$SCRIPT_DIR/../cve/tools/custom_webtech_scanner.sh" "$target" -v 2>/dev/null)
        
        if [[ -n "$webtech_output" ]]; then
            fingerprint_results="Custom Web Technology Scanner Results:
$webtech_output"
            
            print_success "Web technology fingerprinting completed"
            echo "$webtech_output"
            
        else
            print_warning "Custom web technology scanner failed. Performing manual fingerprinting..."
            manual_web_fingerprinting "$target"
        fi
        
    else
        print_warning "Custom web technology scanner not available. Performing manual fingerprinting..."
        manual_web_fingerprinting "$target"
    fi
    
    # Use custom website analyzer for additional insights
    if [[ -f "$SCRIPT_DIR/../cve/tools/custom_website_analyzer.sh" ]]; then
        print_info "Running website size and performance analysis..."
        chmod +x "$SCRIPT_DIR/../cve/tools/custom_website_analyzer.sh"
        
        local analyzer_output=$("$SCRIPT_DIR/../cve/tools/custom_website_analyzer.sh" "$target" 2>/dev/null)
        
        if [[ -n "$analyzer_output" ]]; then
            fingerprint_results="$fingerprint_results

Website Analysis Results:
$analyzer_output"
            
            print_success "Website analysis completed"
        fi
    fi
    
    save_scan_data "web_fingerprinting" "$target" "$fingerprint_results"
    log_scan_result "Web Application Fingerprinting" "$target" "$fingerprint_results"
    
    print_success "Web application fingerprinting completed"
}

manual_web_fingerprinting() {
    local target="$1"
    
    print_info "Performing manual web application fingerprinting..."
    
    # Get basic HTTP response
    local headers=$(curl -s -I "$target" 2>/dev/null)
    local content=$(curl -s "$target" 2>/dev/null)
    
    if [[ -n "$headers" ]]; then
        # Extract server information
        local server=$(echo "$headers" | grep -i "server:" | cut -d: -f2- | xargs)
        [[ -n "$server" ]] && print_success "Server: $server"
        
        # Extract powered-by information
        local powered_by=$(echo "$headers" | grep -i "x-powered-by:" | cut -d: -f2- | xargs)
        [[ -n "$powered_by" ]] && print_success "Powered By: $powered_by"
        
        # Check for framework indicators
        if echo "$content" | grep -qi "wordpress"; then
            print_success "CMS: WordPress detected"
        elif echo "$content" | grep -qi "drupal"; then
            print_success "CMS: Drupal detected"
        elif echo "$content" | grep -qi "joomla"; then
            print_success "CMS: Joomla detected"
        fi
        
        # Check for JavaScript frameworks
        if echo "$content" | grep -qi "react"; then
            print_success "JavaScript Framework: React detected"
        elif echo "$content" | grep -qi "angular"; then
            print_success "JavaScript Framework: Angular detected"
        elif echo "$content" | grep -qi "vue"; then
            print_success "JavaScript Framework: Vue.js detected"
        fi
        
        # Check for common libraries
        if echo "$content" | grep -qi "jquery"; then
            print_success "Library: jQuery detected"
        fi
        
        if echo "$content" | grep -qi "bootstrap"; then
            print_success "CSS Framework: Bootstrap detected"
        fi
    else
        print_error "Failed to retrieve headers for fingerprinting"
    fi
}

# ============================================================================
# Cross-Site Scripting (XSS) Testing
# ============================================================================

xss_testing() {
    local target="$1"
    
    subsection_header "Cross-Site Scripting (XSS) Testing"
    log_scan_start "XSS Testing" "$target"
    
    print_info "Starting XSS testing on $target..."
    
    # Ensure target has protocol
    if [[ ! "$target" =~ ^https?:// ]]; then
        if curl -s --connect-timeout 5 "https://$target" >/dev/null 2>&1; then
            target="https://$target"
        else
            target="http://$target"
        fi
    fi
    
    print_info "Testing for Cross-Site Scripting vulnerabilities..."
    
    # XSS payloads for testing
    local xss_payloads=(
        "<script>alert('XSS')</script>"
        "<img src=x onerror=alert('XSS')>"
        "<svg onload=alert('XSS')>"
        "javascript:alert('XSS')"
        "'\"><script>alert('XSS')</script>"
        "<iframe src=javascript:alert('XSS')></iframe>"
    )
    
    local xss_results=""
    local vulnerabilities_found=0
    
    # Test common parameters
    local test_params=("q" "search" "query" "name" "id" "page" "category" "tag" "user" "comment")
    
    for param in "${test_params[@]}"; do
        print_info "Testing parameter: $param"
        
        for payload in "${xss_payloads[@]}"; do
            local encoded_payload=$(echo "$payload" | sed 's/ /%20/g' | sed 's/</%3C/g' | sed 's/>/%3E/g')
            local test_url="${target}?${param}=${encoded_payload}"
            
            local response=$(curl -s "$test_url" 2>/dev/null)
            
            # Check if payload is reflected in response
            if echo "$response" | grep -q "$payload"; then
                print_error "Potential XSS vulnerability found!"
                print_warning "Parameter: $param"
                print_warning "Payload: $payload"
                print_warning "URL: $test_url"
                
                ((vulnerabilities_found++))
                
                log_vulnerability "Cross-Site Scripting (XSS)" "HIGH" "$target" "XSS vulnerability in parameter: $param" "Payload: $payload, URL: $test_url"
                
                xss_results="$xss_results
XSS Vulnerability Found:
Parameter: $param
Payload: $payload
URL: $test_url
"
                break # Move to next parameter after finding vulnerability
            fi
        done
    done
    
    # Test for DOM-based XSS
    print_info "Testing for DOM-based XSS..."
    local dom_response=$(curl -s "$target" 2>/dev/null)
    
    if echo "$dom_response" | grep -qi "document\.location\|window\.location\|document\.URL\|document\.referrer"; then
        print_warning "Potential DOM-based XSS vectors detected"
        print_info "Manual verification recommended for DOM-based XSS"
        
        xss_results="$xss_results
Potential DOM-based XSS vectors found in JavaScript code.
Manual verification recommended.
"
    fi
    
    # Check for XSS protection headers
    print_info "Checking XSS protection headers..."
    local headers=$(curl -s -I "$target" 2>/dev/null)
    
    if echo "$headers" | grep -qi "X-XSS-Protection"; then
        local xss_protection=$(echo "$headers" | grep -i "X-XSS-Protection" | cut -d: -f2- | xargs)
        print_success "X-XSS-Protection header present: $xss_protection"
    else
        print_warning "X-XSS-Protection header missing"
        log_vulnerability "Missing Security Header" "LOW" "$target" "X-XSS-Protection header not set" "Missing X-XSS-Protection header"
    fi
    
    if echo "$headers" | grep -qi "Content-Security-Policy"; then
        print_success "Content-Security-Policy header present"
    else
        print_warning "Content-Security-Policy header missing"
        log_vulnerability "Missing Security Header" "MEDIUM" "$target" "Content-Security-Policy header not set" "Missing CSP header increases XSS risk"
    fi
    
    # Summary
    if [[ $vulnerabilities_found -gt 0 ]]; then
        print_error "XSS testing completed: $vulnerabilities_found vulnerabilities found"
    else
        print_success "XSS testing completed: No obvious vulnerabilities detected"
    fi
    
    save_scan_data "xss_testing" "$target" "$xss_results"
    log_scan_result "XSS Testing" "$target" "$xss_results"
    
    print_success "Cross-Site Scripting testing completed"
}

# ============================================================================
# Authentication Bypass Testing
# ============================================================================

auth_bypass_testing() {
    local target="$1"
    
    subsection_header "Authentication Bypass Testing"
    log_scan_start "Authentication Bypass Testing" "$target"
    
    print_info "Starting authentication bypass testing on $target..."
    
    # Ensure target has protocol
    if [[ ! "$target" =~ ^https?:// ]]; then
        if curl -s --connect-timeout 5 "https://$target" >/dev/null 2>&1; then
            target="https://$target"
        else
            target="http://$target"
        fi
    fi
    
    local auth_results=""
    
    # Look for login pages
    print_info "Searching for login pages..."
    local login_paths=("login" "admin" "wp-login.php" "wp-admin" "administrator" "auth" "signin" "sign-in" "user/login" "account/login")
    local found_login_pages=()
    
    for path in "${login_paths[@]}"; do
        local login_url="$target/$path"
        local response=$(curl -s -o /dev/null -w "%{http_code}" "$login_url" 2>/dev/null)
        
        if [[ "$response" == "200" || "$response" == "302" ]]; then
            print_success "Login page found: /$path (HTTP $response)"
            found_login_pages+=("$login_url")
        fi
    done
    
    # Save results
    local login_data="Login Page Discovery Results for $target
Generated: $(date)

Found Login Pages:
$(printf '%s\n' "${found_login_pages[@]}")
"
    
    save_scan_data "login_discovery" "$target" "$login_data"
    log_scan_result "Login Page Discovery" "$target" "$login_data"
    
    print_success "Login page discovery completed"
}

# ============================================================================
# Full Web Scan
# ============================================================================

full_web_scan() {
    local target="$1"
    
    section_header "Full Web Vulnerability Scan"
    log_scan_start "Full Web Scan" "$target"
    
    print_info "Starting comprehensive web vulnerability scan on $target..."
    print_warning "This may take considerable time..."
    
    # Perform all web scanning modules
    web_app_fingerprinting "$target"
    echo ""
    
    directory_brute_force "$target"
    echo ""
    
    nikto_web_scan "$target"
    echo ""
    
    sql_injection_testing "$target"
    echo ""
    
    xss_testing "$target"
    echo ""
    
    wordpress_security_scan "$target"
    echo ""
    
    http_security_headers "$target"
    echo ""
    
    auth_bypass_testing "$target"
    
    print_success "Full web vulnerability scan completed"
    log_scan_result "Full Web Scan" "$target" "Comprehensive web vulnerability scan completed"
}

# ============================================================================
# HTTP Security Headers Analysis
# ============================================================================

http_security_headers() {
    local target="$1"
    
    subsection_header "HTTP Security Headers Analysis"
    log_scan_start "HTTP Security Headers" "$target"
    
    print_info "Analyzing HTTP security headers for $target..."
    
    # Ensure target has protocol
    if [[ ! "$target" =~ ^https?:// ]]; then
        if curl -s --connect-timeout 5 "https://$target" >/dev/null 2>&1; then
            target="https://$target"
        else
            target="http://$target"
        fi
    fi
    
    print_info "Target URL: $target"
    
    # Get HTTP headers
    local headers=$(curl -s -I --max-time 10 "$target" 2>/dev/null)
    
    if [[ -n "$headers" ]]; then
        print_success "HTTP headers retrieved"
        
        # Security headers to check
        local security_headers=(
            "X-Frame-Options:Clickjacking protection"
            "X-XSS-Protection:XSS protection"
            "X-Content-Type-Options:MIME sniffing protection"
            "Strict-Transport-Security:HTTPS enforcement"
            "Content-Security-Policy:Content security policy"
            "Referrer-Policy:Referrer policy"
            "Permissions-Policy:Permissions policy"
        )
        
        print_info "Security Headers Analysis:"
        
        for header_info in "${security_headers[@]}"; do
            local header_name=$(echo "$header_info" | cut -d: -f1)
            local header_desc=$(echo "$header_info" | cut -d: -f2)
            
            if echo "$headers" | grep -qi "^$header_name:"; then
                local header_value=$(echo "$headers" | grep -i "^$header_name:" | cut -d: -f2- | xargs)
                print_success "$header_name: $header_value"
            else
                print_warning "$header_name: Missing ($header_desc)"
                log_vulnerability "Missing Security Header" "LOW" "$target" "Missing $header_name header" "$header_desc not implemented"
            fi
        done
        
        # Check for information disclosure headers
        print_info "Information Disclosure Check:"
        
        local disclosure_headers=("Server" "X-Powered-By" "X-AspNet-Version" "X-AspNetMvc-Version")
        
        for header in "${disclosure_headers[@]}"; do
            if echo "$headers" | grep -qi "^$header:"; then
                local header_value=$(echo "$headers" | grep -i "^$header:" | cut -d: -f2- | xargs)
                print_warning "$header: $header_value (Information disclosure)"
                log_vulnerability "Information Disclosure" "LOW" "$target" "$header header present" "Server information disclosed: $header_value"
            else
                print_success "$header: Not present (Good)"
            fi
        done
        
    else
        print_error "Failed to retrieve HTTP headers"
        return 1
    fi
    
    save_scan_data "http_security_headers" "$target" "$headers"
    log_scan_result "HTTP Security Headers" "$target" "$headers"
    
    print_success "HTTP security headers analysis completed"
}

# ============================================================================
# Quick Web Scan
# ============================================================================

quick_web_scan() {
    local target="$1"
    
    section_header "Quick Web Scan"
    log_scan_start "Quick Web Scan" "$target"
    
    print_info "Starting quick web scan on $target..."
    
    # Quick technology detection
    web_technology_fingerprinting "$target"
    echo ""
    
    # Quick directory scan
    quick_directory_scan "$target"
    echo ""
    
    # Basic security headers check
    http_security_headers "$target"
    
    print_success "Quick web scan completed"
    log_scan_result "Quick Web Scan" "$target" "Quick web scan completed"
}

quick_directory_scan() {
    local target="$1"
    
    subsection_header "Quick Directory Scan"
    print_info "Performing quick directory enumeration on $target..."
    
    local common_dirs=("admin" "login" "wp-admin" "administrator" "backup" "config" "test" "dev" "api" "uploads")
    local found_dirs=()
    
    for dir in "${common_dirs[@]}"; do
        local dir_url="$target/$dir"
        local response=$(curl -s -o /dev/null -w "%{http_code}" "$dir_url" 2>/dev/null)
        
        if [[ "$response" == "200" || "$response" == "301" || "$response" == "302" ]]; then
            print_success "Directory found: /$dir (HTTP $response)"
            found_dirs+=("$dir_url")
        fi
    done
    
    if [[ ${#found_dirs[@]} -eq 0 ]]; then
        print_info "No common directories found"
    fi
    
    print_success "Quick directory scan completed"
}
